{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandr001/Data-Mining-MGT7216/blob/development/MGT7216_Sentiment_Analytics_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis using Semi-Supervised Learning - 1**\n",
        "**Self Learning Approach:**"
      ],
      "metadata": {
        "id": "mSSUAC-CRB52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import necessary packages**"
      ],
      "metadata": {
        "id": "P2DJggCvRVse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6fCPMgdVnc",
        "outputId": "8a17d404-5114-46d6-80e3-899a8c80bfb5"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "PLNYtXK8RV1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d08379e-e986-4c54-dcc6-248b8e36af09",
        "collapsed": true
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "from langdetect import detect\n",
        "from googletrans import Translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCjdR8xdQ9X1",
        "outputId": "5756fa96-7b7e-432e-ffbe-ad774f92c68c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=b184810c3de715f0f63d56bb226e361118821565850fadef9d859ff3fbd0fee8\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2024.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17395 sha256=7f61a20fd3ac58736a081a2c3a8133af90d84d2a16e1fa17e5e4aaa7ab2a81f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.4.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/Data Mining/A_II_Emotion_Data_Student_Copy_Final.xlsx\")"
      ],
      "metadata": {
        "id": "UdYUqkaCdem6"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descriptive Statistics**"
      ],
      "metadata": {
        "id": "0LC2aGRPe46q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\033[1mThe dimension of the data:\\033[0m\", df.shape)\n",
        "\n",
        "null_counts = df.isnull().sum()\n",
        "print(\"\\n\\033[1mColumn wise Null value counts:\\033[0m\")\n",
        "print(null_counts)\n",
        "\n",
        "for column in [\"brand_name_\", \"country_\", \"star_rating_\"]:\n",
        "    print(\"\\n\\033[1mUnique levels for column '{}':\\033[0m\".format(column), df[column].unique())\n",
        "\n",
        "print(f\"\\n\\033[1mCount for the Countries:\\033[0m {len(df['country_'].unique())}\")\n",
        "\n",
        "print(f\"\\n\\033[1m Labeled Data Count:\\033[0m {df['emotions_'].notnull().sum()}\")\n",
        "\n",
        "print(f\"\\n\\033[1m Unlabeled Data Count:\\033[0m {df['emotions_'].isnull().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TukuMU5sbLJ9",
        "outputId": "5a0a6cc0-91a3-4ca0-8b59-b7152a485bc4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mThe dimension of the data:\u001b[0m (5722, 6)\n",
            "\n",
            "\u001b[1mColumn wise Null value counts:\u001b[0m\n",
            "ID_                 0\n",
            "brand_name_         0\n",
            "country_            0\n",
            "star_rating_        0\n",
            "emotions_        5095\n",
            "text_reviews_       0\n",
            "dtype: int64\n",
            "\n",
            "\u001b[1mUnique levels for column 'brand_name_':\u001b[0m ['Z_' 'H_']\n",
            "\n",
            "\u001b[1mUnique levels for column 'country_':\u001b[0m ['US' 'GB' 'FRI' 'HR' 'NO' 'IE' 'CA' 'DK' 'PT' 'ES' 'AT' 'IN' 'IT' 'NL'\n",
            " 'DE' 'AU' 'CZ' 'RO' 'FI' 'FR' 'GR' 'SI' 'HK' 'HU' 'MY' 'UA' 'MX' 'TR'\n",
            " 'ZA' 'BE' 'RS' 'AE' 'SE' 'EN' 'CH' 'MAL' 'PL' 'LV' 'MK' 'IS' 'LB' 'PH'\n",
            " 'JP' 'SG' 'LU' 'PE' 'SK' 'LT' 'BR' 'CO' 'TN' 'TH' 'CY' 'IL' 'HN' 'DO'\n",
            " 'VN' 'CL' 'AR' 'UY' 'IR' 'PK' 'PA' 'NZ' 'GE' 'RE' 'MT' 'VE' 'CW' 'NI'\n",
            " 'PR' 'AM' 'CN' 'KR' 'MQ' 'BG' 'MA' 'ID' 'EC' 'BD' 'EE' 'DZ' 'SX' 'KE'\n",
            " 'AL' 'RU' 'SM' 'XK' 'JM' '.PL' 'MD' 'OM' 'BF']\n",
            "\n",
            "\u001b[1mUnique levels for column 'star_rating_':\u001b[0m [5 1 2 3 4]\n",
            "\n",
            "\u001b[1mCount for the Countries:\u001b[0m 93\n",
            "\n",
            "\u001b[1m Labeled Data Count:\u001b[0m 627\n",
            "\n",
            "\u001b[1m Unlabeled Data Count:\u001b[0m 5095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews_filtered = df.dropna(subset=['text_reviews_']).loc[df['text_reviews_'] != '']\n",
        "\n",
        "# Function to detect language\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        lang = detect(text)\n",
        "        return lang\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "# Apply language detection function to the text reviews column\n",
        "df_reviews_filtered['language'] = df_reviews_filtered['text_reviews_'].apply(detect_language)\n",
        "\n",
        "# Count the number of text reviews that are not in English or are empty\n",
        "non_english_count = df_reviews_filtered[(df_reviews_filtered['language'] != 'en')].shape[0]\n",
        "\n",
        "print(\"Count for text reviews that are not in English or are empty:\", non_english_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPC3F6Ylml5p",
        "outputId": "9cc31644-f8ee-42a8-9dc1-3ea944bbd713"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count for text reviews that are not in English or are empty: 2923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a Definition: Custom cleaning function**"
      ],
      "metadata": {
        "id": "zGDDdccrRV9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "\n",
        "# Translate non-English texts to English\n",
        "def translate_to_english(text):\n",
        "    try:\n",
        "        # Check if the language of the text is not English\n",
        "        if detect(text) != 'en':\n",
        "            translated_text = translator.translate(text, dest='en').text\n",
        "            return translated_text\n",
        "        else:\n",
        "            return text  # Return original text if already in English\n",
        "    except:\n",
        "        return text  # Return original text if translation fails\n",
        "\n",
        "# Apply translation to non-English texts\n",
        "df['formatted_reviews'] = df['text_reviews_'].apply(translate_to_english)\n",
        "\n",
        "# Print the DataFrame to verify the translated texts\n",
        "print(df['formatted_reviews'])"
      ],
      "metadata": {
        "id": "4bIt7a2h6OHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d18078a-2390-4065-d431-34d2f4be97b4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       Fast shipping! All cloths was finally fits wel...\n",
            "1       Just wanted to say how delighted I was with th...\n",
            "2       My order took 6 days with a snow day and a wee...\n",
            "3       Wouldnt give them no stars. I ordered a coat 4...\n",
            "4       Parcel never arrived. Chasing for a refund for...\n",
            "                              ...                        \n",
            "5717    IÃÂ¯ÃÂ¾ÃÆÃÂ£ÃÆÃÂ£ÃÂ¯ÃÂ¾ÃÆÃÂ¯ÃÂ½Ã...\n",
            "5718    I wanted to change the delivery location of my...\n",
            "5719    Waiting since 24/14/2022. I believe the sent m...\n",
            "5720    Who do you complain to about late deliveries f...\n",
            "5721    Placed an order on the 24th November. H_ alert...\n",
            "Name: formatted_reviews, Length: 5722, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n",
        "    text = text.lower()  # Lowercase text\n",
        "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)  # Remove words with 1 or 2 letters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Keep text with letters and spaces\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "6hbJrLMyMbOn"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean the Reviews**"
      ],
      "metadata": {
        "id": "lRUz3B9nMizx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_reviews'] = df['formatted_reviews'].apply(clean_text)\n",
        "print(\"Total cleaned reviews = \", len(df['cleaned_reviews']), \"\\n\\n\", df[\"cleaned_reviews\"])"
      ],
      "metadata": {
        "id": "A875mU2PPx93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152dcdf9-828d-452f-8952-7901868b08a8",
        "collapsed": true
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total cleaned reviews =  5722 \n",
            "\n",
            " 0          fast shipping cloth finally fit well satisfied\n",
            "1       wanted say delighted friendly helpful staff me...\n",
            "2       order took day snow day weekend happy sweater ...\n",
            "3       wouldnt give star ordered coat week ago receiv...\n",
            "4       parcel never arrived chasing refund substantia...\n",
            "                              ...                        \n",
            "5717    given star could known evri hermes courier wou...\n",
            "5718    wanted change delivery location item within ho...\n",
            "5719    waiting since believe sent order wrong country...\n",
            "5720    complain late delivery horrendous compnay revi...\n",
            "5721    placed order th november alert order could tak...\n",
            "Name: cleaned_reviews, Length: 5722, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform Self-Learning**"
      ],
      "metadata": {
        "id": "V_OSjtjaK6Jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into labeled and unlabeled"
      ],
      "metadata": {
        "id": "2ofUkkHwMWh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unlabeled_data = df[df['emotions_'] == 'NaN'][['cleaned_reviews']]\n",
        "\n",
        "unlabeled_data = df[pd.isnull(df['emotions_'])][['cleaned_reviews']]\n",
        "\n",
        "print(len(unlabeled_data))\n",
        "\n",
        "unlabeled_data['emotions_'] = -1\n",
        "\n",
        "unlabeled_data"
      ],
      "metadata": {
        "id": "uWxp6OE9MTdR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "2e5329ad-9ebf-4ce2-a9ba-1b928e952945"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5095\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        cleaned_reviews  emotions_\n",
              "0        fast shipping cloth finally fit well satisfied         -1\n",
              "1     wanted say delighted friendly helpful staff me...         -1\n",
              "4     parcel never arrived chasing refund substantia...         -1\n",
              "5     avoid ordering online ordered day ago evri pac...         -1\n",
              "6     awful service returning item booked collection...         -1\n",
              "...                                                 ...        ...\n",
              "5717  given star could known evri hermes courier wou...         -1\n",
              "5718  wanted change delivery location item within ho...         -1\n",
              "5719  waiting since believe sent order wrong country...         -1\n",
              "5720  complain late delivery horrendous compnay revi...         -1\n",
              "5721  placed order th november alert order could tak...         -1\n",
              "\n",
              "[5095 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b623467-f0c7-4c9d-9d88-90be6316c813\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_reviews</th>\n",
              "      <th>emotions_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fast shipping cloth finally fit well satisfied</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wanted say delighted friendly helpful staff me...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>parcel never arrived chasing refund substantia...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>avoid ordering online ordered day ago evri pac...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>awful service returning item booked collection...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5717</th>\n",
              "      <td>given star could known evri hermes courier wou...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5718</th>\n",
              "      <td>wanted change delivery location item within ho...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5719</th>\n",
              "      <td>waiting since believe sent order wrong country...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5720</th>\n",
              "      <td>complain late delivery horrendous compnay revi...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5721</th>\n",
              "      <td>placed order th november alert order could tak...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5095 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b623467-f0c7-4c9d-9d88-90be6316c813')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b623467-f0c7-4c9d-9d88-90be6316c813 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b623467-f0c7-4c9d-9d88-90be6316c813');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e0ffb43-bbde-4861-81c9-8b0801a24eca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e0ffb43-bbde-4861-81c9-8b0801a24eca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e0ffb43-bbde-4861-81c9-8b0801a24eca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "unlabeled_data",
              "summary": "{\n  \"name\": \"unlabeled_data\",\n  \"rows\": 5095,\n  \"fields\": [\n    {\n      \"column\": \"cleaned_reviews\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4999,\n        \"samples\": [\n          \"even give one star placed order next day delivery received notification say dispatched receive contacted time given answer order never buy\",\n          \"customer service best friendly understand blocked account take fourteen day unblocked speak safety order anything online pay mastercard\",\n          \"love abusing sale pack item well got item quickly bit expensive buying name always ebay\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotions_\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": -1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract X and y from labeled_data**"
      ],
      "metadata": {
        "id": "xv1ZSTi6MTkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define labeled data as data where \"Sentiment\" is not missing\n",
        "labeled_data = df[df['emotions_'].notnull() & (df['emotions_'] != 'NaN')]\n",
        "\n",
        "print(\"Labeled data count:\", len(labeled_data))\n",
        "\n",
        "# Extract labels from labeled_data\n",
        "y_labeled = labeled_data['emotions_']\n",
        "y_unlabeled = unlabeled_data['emotions_']\n",
        "X_labeled = labeled_data['cleaned_reviews']\n",
        "X_unlabeled = unlabeled_data['cleaned_reviews']\n",
        "\n",
        "# print(\"y_labeled \",y_labeled )\n",
        "# print(\"y_unlabeled\",y_unlabeled)\n",
        "# print(\"X_unlabeled\",X_unlabeled)\n",
        "# print(\"X_labeled\",X_labeled)\n"
      ],
      "metadata": {
        "id": "O9yJqZarMTrm",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a2201e-6c86-4433-cb37-d882bf501891"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled data count: 627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipelines**"
      ],
      "metadata": {
        "id": "GVR3p1SY0tHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC  # Import Support Vector Classification\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Parameters\n",
        "svm_params = dict(decision_function_shape='ovo', C=1.0, kernel='linear', gamma='auto', probability=True, random_state=42)\n",
        "# hyper_parameters = {\n",
        "#                     'kernel': ['linear'],\n",
        "#                     'C': [0.01, 0.1],\n",
        "#                     'gamma': [0.01, 0.1]}\n",
        "\n",
        "vectorizer_params = dict(ngram_range=(1, 2), min_df=1, max_df=0.8)\n",
        "\n",
        "# Supervised Pipeline with SVM\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
        "        (\"tfidf\", TfidfTransformer()),\n",
        "        # (\"clf\", GridSearchCV(SVC(**svm_params), param_grid=hyper_parameters, cv=5))\n",
        "        (\"clf\", SVC(**svm_params)),\n",
        "    ]\n",
        ")\n",
        "# SelfTraining Pipeline\n",
        "st_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
        "        (\"tfidf\", TfidfTransformer()),\n",
        "        (\"clf\", SelfTrainingClassifier(SVC(**svm_params), verbose=True)),\n",
        "        # (\"clf\", SelfTrainingClassifier(GridSearchCV(SVC(**svm_params), param_grid=hyper_parameters, cv=3), verbose=True)),\n",
        "\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "3gNSgU9S0tN1"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a function for a classification report**"
      ],
      "metadata": {
        "id": "aXhq1Peu0S00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test, predict_df_unlabeled=0):\n",
        "    print(\"\\n\\033[1mNumber of training samples:\\033[0m\", len(X_train))\n",
        "    print(\"\\n\\033[1mUnlabeled samples in training set:\\033[0m\", sum(1 for x in y_train if x == -1)) #if x == NULL\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    #print(\"y Train\", y_train)\n",
        "\n",
        "    print(\"\\ny Test\",y_test)\n",
        "    print(\"\\ny Predict\",y_pred)\n",
        "\n",
        "    print(\n",
        "        \"\\n\\033[1mMicro-averaged F1 score on test set:\\033[0m %0.3f\"\n",
        "        % f1_score(y_test, y_pred, average=\"micro\")\n",
        "    )\n",
        "    print(\"\\n\\033[1m\\nConfusion Matrix:\\033[0m\", confusion_matrix(y_test,y_pred))\n",
        "    print(\"\\n\\033[1mClassification Report:\\033[0m\", classification_report(y_test, y_pred,zero_division=1))\n",
        "\n",
        "    if predict_df_unlabeled:\n",
        "      # Predict emotions in dataframe for text data without labels and saving to column ypred_emotions\n",
        "      ypred_emotions = clf.predict(df[df['emotions_'].isnull()]['cleaned_reviews'])\n",
        "\n",
        "      # Assign the predicted emotions to a new column in the DataFrame\n",
        "      df.loc[df['emotions_'].isnull(), 'ypred_emotions'] = ypred_emotions\n",
        "      print(len(df['ypred_emotions']))\n",
        "\n",
        "      # Reverse the label_mapping dictionary\n",
        "      reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "      # Convert predicted labels to emotions\n",
        "      df['ypred_emotions'] = df['ypred_emotions'].map(reverse_label_mapping)\n",
        "\n",
        "      print(df['ypred_emotions'])"
      ],
      "metadata": {
        "id": "vEtYi3z20S7l"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data**"
      ],
      "metadata": {
        "id": "-EFccLfJ0Jpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, stratify=y_labeled, random_state=42)\n",
        "\n",
        "print(len(X_train), len(y_train), len(X_test), len(y_test))"
      ],
      "metadata": {
        "id": "Xe0jIcaq0Jw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7437ac34-f8d5-4412-a032-9e603b962bbc"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "501 501 126 126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supervised SVM Classifier on the labeled data**"
      ],
      "metadata": {
        "id": "0xoWkJmgyqnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Supervised SVM Classifier on the labeled data:\")\n",
        "y_pred = eval_and_print_metrics(pipeline, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-49aaJ-lyquw",
        "outputId": "4943ec33-e867-4e50-d67f-cadfbcb6d9ad",
        "collapsed": true
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supervised SVM Classifier on the labeled data:\n",
            "\n",
            "\u001b[1mNumber of training samples:\u001b[0m 501\n",
            "\n",
            "\u001b[1mUnlabeled samples in training set:\u001b[0m 0\n",
            "\n",
            "y Test 304     surprise\n",
            "57           joy\n",
            "912     surprise\n",
            "3367    surprise\n",
            "2820     neutral\n",
            "          ...   \n",
            "703        anger\n",
            "2687     neutral\n",
            "3339    surprise\n",
            "1674     sadness\n",
            "4890    surprise\n",
            "Name: emotions_, Length: 126, dtype: object\n",
            "\n",
            "y Predict ['surprise' 'joy' 'surprise' 'surprise' 'neutral' 'joy' 'surprise'\n",
            " 'surprise' 'disgust' 'surprise' 'sadness' 'surprise' 'joy' 'joy' 'joy'\n",
            " 'disgust' 'anger' 'sadness' 'neutral' 'sadness' 'sadness' 'surprise'\n",
            " 'joy' 'neutral' 'sadness' 'disgust' 'sadness' 'disgust' 'surprise'\n",
            " 'anger' 'disgust' 'neutral' 'disgust' 'neutral' 'sadness' 'sadness'\n",
            " 'sadness' 'surprise' 'disgust' 'surprise' 'sadness' 'sadness' 'disgust'\n",
            " 'fear' 'sadness' 'surprise' 'disgust' 'neutral' 'sadness' 'surprise'\n",
            " 'sadness' 'surprise' 'fear' 'sadness' 'fear' 'neutral' 'disgust'\n",
            " 'neutral' 'surprise' 'joy' 'fear' 'surprise' 'neutral' 'joy' 'sadness'\n",
            " 'surprise' 'joy' 'neutral' 'disgust' 'surprise' 'surprise' 'surprise'\n",
            " 'surprise' 'anger' 'neutral' 'fear' 'surprise' 'disgust' 'surprise'\n",
            " 'sadness' 'surprise' 'fear' 'disgust' 'fear' 'neutral' 'sadness' 'joy'\n",
            " 'neutral' 'joy' 'joy' 'disgust' 'surprise' 'joy' 'sadness' 'joy'\n",
            " 'sadness' 'surprise' 'sadness' 'joy' 'fear' 'sadness' 'neutral'\n",
            " 'surprise' 'joy' 'neutral' 'disgust' 'disgust' 'sadness' 'disgust'\n",
            " 'surprise' 'neutral' 'fear' 'surprise' 'anger' 'fear' 'neutral'\n",
            " 'surprise' 'surprise' 'neutral' 'joy' 'surprise' 'surprise' 'surprise'\n",
            " 'joy' 'neutral' 'disgust']\n",
            "\n",
            "\u001b[1mMicro-averaged F1 score on test set:\u001b[0m 0.500\n",
            "\n",
            "\u001b[1m\n",
            "Confusion Matrix:\u001b[0m [[ 3  1  0  1  2  2  2]\n",
            " [ 1  8  1  1  1  2  2]\n",
            " [ 0  2  6  1  0  4  3]\n",
            " [ 0  0  1 12  0  3  4]\n",
            " [ 0  2  0  0 11  1  6]\n",
            " [ 0  2  1  2  5  8  2]\n",
            " [ 0  3  1  1  0  3 15]]\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.75      0.27      0.40        11\n",
            "     disgust       0.44      0.50      0.47        16\n",
            "        fear       0.60      0.38      0.46        16\n",
            "         joy       0.67      0.60      0.63        20\n",
            "     neutral       0.58      0.55      0.56        20\n",
            "     sadness       0.35      0.40      0.37        20\n",
            "    surprise       0.44      0.65      0.53        23\n",
            "\n",
            "    accuracy                           0.50       126\n",
            "   macro avg       0.55      0.48      0.49       126\n",
            "weighted avg       0.53      0.50      0.50       126\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self Training Classifier on the labeled data**"
      ],
      "metadata": {
        "id": "ZOhbZGWzz6wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Self Training Classifier on the labeled data:\")\n",
        "eval_and_print_metrics(st_pipeline, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KlRuPUTz62U",
        "outputId": "d5994a7c-f515-43b4-98c6-7099bdfe3c33"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self Training Classifier on the labeled data:\n",
            "\n",
            "\u001b[1mNumber of training samples:\u001b[0m 501\n",
            "\n",
            "\u001b[1mUnlabeled samples in training set:\u001b[0m 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/semi_supervised/_self_training.py:212: UserWarning: y contains no unlabeled samples\n",
            "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "y Test 304     surprise\n",
            "57           joy\n",
            "912     surprise\n",
            "3367    surprise\n",
            "2820     neutral\n",
            "          ...   \n",
            "703        anger\n",
            "2687     neutral\n",
            "3339    surprise\n",
            "1674     sadness\n",
            "4890    surprise\n",
            "Name: emotions_, Length: 126, dtype: object\n",
            "\n",
            "y Predict ['surprise' 'joy' 'surprise' 'surprise' 'neutral' 'joy' 'surprise'\n",
            " 'surprise' 'disgust' 'surprise' 'sadness' 'surprise' 'joy' 'joy' 'joy'\n",
            " 'disgust' 'anger' 'sadness' 'neutral' 'sadness' 'sadness' 'surprise'\n",
            " 'joy' 'neutral' 'sadness' 'disgust' 'sadness' 'disgust' 'surprise'\n",
            " 'anger' 'disgust' 'neutral' 'disgust' 'neutral' 'sadness' 'sadness'\n",
            " 'sadness' 'surprise' 'disgust' 'surprise' 'sadness' 'sadness' 'disgust'\n",
            " 'fear' 'sadness' 'surprise' 'disgust' 'neutral' 'sadness' 'surprise'\n",
            " 'sadness' 'surprise' 'fear' 'sadness' 'fear' 'neutral' 'disgust'\n",
            " 'neutral' 'surprise' 'joy' 'fear' 'surprise' 'neutral' 'joy' 'sadness'\n",
            " 'surprise' 'joy' 'neutral' 'disgust' 'surprise' 'surprise' 'surprise'\n",
            " 'surprise' 'anger' 'neutral' 'fear' 'surprise' 'disgust' 'surprise'\n",
            " 'sadness' 'surprise' 'fear' 'disgust' 'fear' 'neutral' 'sadness' 'joy'\n",
            " 'neutral' 'joy' 'joy' 'disgust' 'surprise' 'joy' 'sadness' 'joy'\n",
            " 'sadness' 'surprise' 'sadness' 'joy' 'fear' 'sadness' 'neutral'\n",
            " 'surprise' 'joy' 'neutral' 'disgust' 'disgust' 'sadness' 'disgust'\n",
            " 'surprise' 'neutral' 'fear' 'surprise' 'anger' 'fear' 'neutral'\n",
            " 'surprise' 'surprise' 'neutral' 'joy' 'surprise' 'surprise' 'surprise'\n",
            " 'joy' 'neutral' 'disgust']\n",
            "\n",
            "\u001b[1mMicro-averaged F1 score on test set:\u001b[0m 0.500\n",
            "\n",
            "\u001b[1m\n",
            "Confusion Matrix:\u001b[0m [[ 3  1  0  1  2  2  2]\n",
            " [ 1  8  1  1  1  2  2]\n",
            " [ 0  2  6  1  0  4  3]\n",
            " [ 0  0  1 12  0  3  4]\n",
            " [ 0  2  0  0 11  1  6]\n",
            " [ 0  2  1  2  5  8  2]\n",
            " [ 0  3  1  1  0  3 15]]\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.75      0.27      0.40        11\n",
            "     disgust       0.44      0.50      0.47        16\n",
            "        fear       0.60      0.38      0.46        16\n",
            "         joy       0.67      0.60      0.63        20\n",
            "     neutral       0.58      0.55      0.56        20\n",
            "     sadness       0.35      0.40      0.37        20\n",
            "    surprise       0.44      0.65      0.53        23\n",
            "\n",
            "    accuracy                           0.50       126\n",
            "   macro avg       0.55      0.48      0.49       126\n",
            "weighted avg       0.53      0.50      0.50       126\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self Training Classifier on the labeled and unlabeled data**"
      ],
      "metadata": {
        "id": "bAacD-vPyq8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manage Labeled and Unlabeled Data**"
      ],
      "metadata": {
        "id": "-k79s34Oy8Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_indices = X_test.index\n",
        "#print(\"TEST INDICES\",test_indices)\n",
        "\n",
        "# Exclude test data from X_labeled and y_labeled based on the identified indices\n",
        "X_labeled_filtered = X_labeled.drop(index=test_indices, errors='ignore')\n",
        "y_labeled_filtered = y_labeled.drop(index=test_indices, errors='ignore')\n",
        "\n",
        "# Concatenate the filtered labeled data with the unlabeled data\n",
        "X=X_combined = pd.concat([X_labeled_filtered, X_unlabeled])\n",
        "y=y_combined = pd.concat([y_labeled_filtered, y_unlabeled])\n"
      ],
      "metadata": {
        "id": "s8Mo7t2vy8O3"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mapping Labels**"
      ],
      "metadata": {
        "id": "FNiE_v17y8X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping for labels\n",
        "# label_mapping = {'Positive': 1, 'Negative': 0, -1:-1 }\n",
        "label_mapping = {\n",
        "    'anger': 1,\n",
        "    'joy': 2,\n",
        "    'sadness': 3,\n",
        "    'fear': 4,\n",
        "    'disgust': 5,\n",
        "    'surprise': 6,\n",
        "    'neutral': 7,\n",
        "    -1:-1\n",
        "}\n",
        "# Apply the mapping to labels\n",
        "y  = [label_mapping[label] for label in y]\n",
        "#print(y)\n",
        "y_test  = [label_mapping[label] for label in y_test]\n",
        "#print(y_test)"
      ],
      "metadata": {
        "id": "37vfBIrVy8gD"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Self Training Classifier on the labeled and unlabeled data:\")\n",
        "y_pred = eval_and_print_metrics(st_pipeline, X, y, X_test, y_test, predict_df_unlabeled=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJaJenyyyrEF",
        "outputId": "29f4edfa-9383-437a-dd77-c886f59e3891"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self Training Classifier on the labeled and unlabeled data:\n",
            "\n",
            "\u001b[1mNumber of training samples:\u001b[0m 5596\n",
            "\n",
            "\u001b[1mUnlabeled samples in training set:\u001b[0m 5095\n",
            "End of iteration 1, added 170 new labels.\n",
            "End of iteration 2, added 346 new labels.\n",
            "End of iteration 3, added 779 new labels.\n",
            "End of iteration 4, added 444 new labels.\n",
            "End of iteration 5, added 165 new labels.\n",
            "End of iteration 6, added 235 new labels.\n",
            "End of iteration 7, added 174 new labels.\n",
            "End of iteration 8, added 170 new labels.\n",
            "End of iteration 9, added 178 new labels.\n",
            "End of iteration 10, added 188 new labels.\n",
            "\n",
            "y Test [6, 2, 6, 6, 7, 3, 6, 7, 5, 6, 1, 1, 2, 2, 2, 6, 5, 1, 7, 7, 6, 7, 2, 3, 2, 5, 4, 5, 6, 1, 5, 7, 3, 7, 4, 2, 5, 6, 4, 5, 4, 3, 7, 6, 3, 7, 7, 7, 5, 6, 3, 2, 3, 2, 4, 7, 5, 7, 6, 2, 4, 7, 3, 1, 3, 6, 5, 3, 6, 2, 4, 5, 4, 1, 1, 4, 7, 5, 3, 4, 6, 5, 3, 2, 7, 6, 2, 7, 2, 3, 5, 6, 2, 3, 2, 6, 2, 3, 2, 4, 3, 5, 3, 2, 1, 5, 1, 3, 4, 4, 7, 4, 2, 1, 4, 3, 6, 6, 7, 4, 6, 1, 7, 6, 3, 6]\n",
            "\n",
            "y Predict [5 2 2 7 7 2 2 7 5 6 2 2 2 2 2 5 1 7 7 2 5 7 2 7 4 5 4 5 2 1 5 7 5 7 7 2 7\n",
            " 6 5 2 4 7 7 4 4 7 2 7 5 6 5 7 4 7 4 2 5 7 4 2 4 4 2 2 4 6 2 2 5 2 4 4 7 1\n",
            " 2 7 2 2 7 4 7 7 5 2 7 7 2 7 2 2 5 4 2 3 2 7 2 7 2 4 3 7 4 2 7 5 5 4 5 2 7\n",
            " 4 7 1 4 7 7 2 7 7 6 7 6 2 2 5]\n",
            "\n",
            "\u001b[1mMicro-averaged F1 score on test set:\u001b[0m 0.452\n",
            "\n",
            "\u001b[1m\n",
            "Confusion Matrix:\u001b[0m [[ 3  4  0  0  1  0  3]\n",
            " [ 0 16  0  1  0  0  3]\n",
            " [ 0  5  2  5  3  0  5]\n",
            " [ 0  1  0  9  2  0  4]\n",
            " [ 1  3  0  1  8  0  3]\n",
            " [ 0  5  0  3  5  5  5]\n",
            " [ 0  4  0  1  0  1 14]]\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.27      0.40        11\n",
            "           2       0.42      0.80      0.55        20\n",
            "           3       1.00      0.10      0.18        20\n",
            "           4       0.45      0.56      0.50        16\n",
            "           5       0.42      0.50      0.46        16\n",
            "           6       0.83      0.22      0.34        23\n",
            "           7       0.38      0.70      0.49        20\n",
            "\n",
            "    accuracy                           0.45       126\n",
            "   macro avg       0.61      0.45      0.42       126\n",
            "weighted avg       0.61      0.45      0.41       126\n",
            "\n",
            "5722\n",
            "0           joy\n",
            "1       neutral\n",
            "2           NaN\n",
            "3           NaN\n",
            "4       neutral\n",
            "         ...   \n",
            "5717       fear\n",
            "5718    neutral\n",
            "5719       fear\n",
            "5720    neutral\n",
            "5721       fear\n",
            "Name: ypred_emotions, Length: 5722, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to combine values from emotions_ and ypred_emotions columns\n",
        "def combine_emotions(row):\n",
        "    if pd.notnull(row['emotions_']):\n",
        "        return row['emotions_']\n",
        "    else:\n",
        "        return row['ypred_emotions']\n",
        "\n",
        "# Apply the function to create the emotions_combined column\n",
        "df['emotions_combined'] = df.apply(combine_emotions, axis=1)\n",
        "\n",
        "# Specify the file path where you want to save the CSV file\n",
        "file_path = \"output.csv\"\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "df.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "id": "sgisN9XFNa8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}