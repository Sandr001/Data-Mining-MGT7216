{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandr001/Data-Mining-MGT7216/blob/development/MGT7216_Sentiment_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis using Semi-Supervised Learning - 1**\n",
        "**Self Learning Approach:**"
      ],
      "metadata": {
        "id": "mSSUAC-CRB52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import necessary packages**"
      ],
      "metadata": {
        "id": "P2DJggCvRVse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6fCPMgdVnc",
        "outputId": "e15647f1-36e7-4827-86fb-29c0b887dc60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "PLNYtXK8RV1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46636f81-8223-40eb-ecae-bb203d08a5a5",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/Data Mining/A_II_Emotion_Data_Student_Copy_Final.xlsx\")"
      ],
      "metadata": {
        "id": "UdYUqkaCdem6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a Definition: Custom cleaning function**"
      ],
      "metadata": {
        "id": "zGDDdccrRV9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n",
        "    text = text.lower()  # Lowercase text\n",
        "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)  # Remove words with 1 or 2 letters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Keep text with letters and spaces\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "6hbJrLMyMbOn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean the Reviews**"
      ],
      "metadata": {
        "id": "lRUz3B9nMizx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_reviews'] = df['text_reviews_'].apply(clean_text)\n",
        "print(df[\"cleaned_reviews\"])"
      ],
      "metadata": {
        "id": "A875mU2PPx93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb44a2f6-3865-43cc-d775-142c1abc7409",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0          fast shipping cloth finally fit well satisfied\n",
            "1       wanted say delighted friendly helpful staff me...\n",
            "2       order took day snow day weekend happy sweater ...\n",
            "3       wouldnt give star ordered coat week ago receiv...\n",
            "4       parcel never arrived chasing refund substantia...\n",
            "                              ...                        \n",
            "5717    given star could known evri hermes courier wou...\n",
            "5718    wanted change delivery location item within ho...\n",
            "5719    waiting since believe sent order wrong country...\n",
            "5720    complain late delivery horrendous compnay revi...\n",
            "5721    placed order th november alert order could tak...\n",
            "Name: cleaned_reviews, Length: 5722, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langdetect\n",
        "# !pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCjdR8xdQ9X1",
        "outputId": "a111274d-3030-4eb7-85c1-ddaa7edfabdf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.4.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "from langdetect import detect\n",
        "\n",
        "# Assuming df is your DataFrame and 'Text Reviews' is the column containing text reviews\n",
        "translator = Translator()\n",
        "\n",
        "# Translate non-English texts to English\n",
        "def translate_to_english(text):\n",
        "    try:\n",
        "        # Check if the language of the text is not English\n",
        "        if detect(text) != 'en':\n",
        "            translated_text = translator.translate(text, dest='en').text\n",
        "            return translated_text\n",
        "        else:\n",
        "            return text  # Return original text if already in English\n",
        "    except:\n",
        "        return text  # Return original text if translation fails\n",
        "\n",
        "# Apply translation to non-English texts\n",
        "df['cleaned_reviews'] = df['cleaned_reviews'].apply(translate_to_english)\n",
        "\n",
        "# Print the DataFrame to verify the translated texts\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "4bIt7a2h6OHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform Self-Learning**"
      ],
      "metadata": {
        "id": "V_OSjtjaK6Jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into labeled and unlabeled"
      ],
      "metadata": {
        "id": "2ofUkkHwMWh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled_data = df[df['emotions_'] == 'NaN'][['cleaned_reviews']]\n",
        "unlabeled_data['emotions_'] = -1\n",
        "print(unlabeled_data)"
      ],
      "metadata": {
        "id": "uWxp6OE9MTdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5904a4d6-4e72-4d5d-d2a2-9e5a70f20019"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [cleaned_reviews, emotions_]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract X and y from labeled_data**"
      ],
      "metadata": {
        "id": "xv1ZSTi6MTkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define labeled data as data where \"Sentiment\" is not missing\n",
        "labeled_data = df[df['emotions_'].notna() & (df['emotions_'] != 'NaN')]\n",
        "# Extract labels from labeled_data\n",
        "y_labeled = labeled_data['emotions_']\n",
        "y_unlabeled = unlabeled_data['emotions_']\n",
        "X_labeled = labeled_data['cleaned_reviews']\n",
        "X_unlabeled = unlabeled_data['cleaned_reviews']\n",
        "\n",
        "print(\"y_labeled \",y_labeled )\n",
        "print(\"y_unlabeled\",y_unlabeled)\n",
        "print(\"X_unlabeled\",X_unlabeled)\n",
        "print(\"X_labeled\",X_labeled)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "O9yJqZarMTrm",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b14da69-bc2f-4f08-a0c3-46ff421bb53f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_labeled  2            joy\n",
            "3           fear\n",
            "10      surprise\n",
            "18         anger\n",
            "25       neutral\n",
            "          ...   \n",
            "5692     sadness\n",
            "5695        fear\n",
            "5701       anger\n",
            "5711         joy\n",
            "5715       anger\n",
            "Name: emotions_, Length: 627, dtype: object\n",
            "y_unlabeled Series([], Name: emotions_, dtype: int64)\n",
            "X_unlabeled Series([], Name: cleaned_reviews, dtype: object)\n",
            "X_labeled 2       order took day snow day weekend happy sweater ...\n",
            "3       wouldnt give star ordered coat week ago receiv...\n",
            "10      went glasgow saturday bought kid stuff nd floo...\n",
            "18      trying order product online cost option click ...\n",
            "25                                               use evri\n",
            "                              ...                        \n",
            "5692     dont order online store tooooo much headache prb\n",
            "5695    use evri formally hermes courier lost confiden...\n",
            "5701    staff westfield stratford rude went voucher vo...\n",
            "5711    packet came week super satisfiedeverything fit...\n",
            "5715    received item wrong colour damaged contacted c...\n",
            "Name: cleaned_reviews, Length: 627, dtype: object\n",
            "         ID_ brand_name_ country_  star_rating_ emotions_  \\\n",
            "0        ID1          Z_       US             5       NaN   \n",
            "1       ID10          Z_       GB             5       NaN   \n",
            "2      ID100          H_      FRI             5       joy   \n",
            "3     ID1000          H_       GB             1      fear   \n",
            "4     ID1001          H_       GB             1       NaN   \n",
            "...      ...         ...      ...           ...       ...   \n",
            "5717   ID995          H_       GB             1       NaN   \n",
            "5718   ID996          H_       GB             1       NaN   \n",
            "5719   ID997          H_       CY             1       NaN   \n",
            "5720   ID998          H_       GB             1       NaN   \n",
            "5721   ID999          H_       NL             1       NaN   \n",
            "\n",
            "                                          text_reviews_  \\\n",
            "0     Fast shipping! All cloths was finally fits wel...   \n",
            "1     Just wanted to say how delighted I was with th...   \n",
            "2     My order took 6 days with a snow day and a wee...   \n",
            "3     Wouldnt give them no stars. I ordered a coat 4...   \n",
            "4     Parcel never arrived. Chasing for a refund for...   \n",
            "...                                                 ...   \n",
            "5717  IÃÂ¯ÃÂ¾ÃÆÃÂ£ÃÆÃÂ£ÃÂ¯ÃÂ¾ÃÆÃÂ¯ÃÂ½Ã...   \n",
            "5718  I wanted to change the delivery location of my...   \n",
            "5719  Waiting since 24/14/2022. I believe the sent m...   \n",
            "5720  Who do you complain to about late deliveries f...   \n",
            "5721  Placed an order on the 24th November. H_ alert...   \n",
            "\n",
            "                                        cleaned_reviews  \n",
            "0        fast shipping cloth finally fit well satisfied  \n",
            "1     wanted say delighted friendly helpful staff me...  \n",
            "2     order took day snow day weekend happy sweater ...  \n",
            "3     wouldnt give star ordered coat week ago receiv...  \n",
            "4     parcel never arrived chasing refund substantia...  \n",
            "...                                                 ...  \n",
            "5717  given star could known evri hermes courier wou...  \n",
            "5718  wanted change delivery location item within ho...  \n",
            "5719  waiting since believe sent order wrong country...  \n",
            "5720  complain late delivery horrendous compnay revi...  \n",
            "5721  placed order th november alert order could tak...  \n",
            "\n",
            "[5722 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipelines**"
      ],
      "metadata": {
        "id": "GVR3p1SY0tHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "sdg_params = dict(alpha=1e-5, penalty=\"l2\", loss=\"log_loss\")\n",
        "vectorizer_params = dict(ngram_range=(1, 2), min_df=1, max_df=0.8)\n",
        "\n",
        "# Supervised Pipeline\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
        "        (\"tfidf\", TfidfTransformer()),\n",
        "        (\"clf\", SGDClassifier(**sdg_params)),\n",
        "    ]\n",
        ")\n",
        "# SelfTraining Pipeline\n",
        "st_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
        "        (\"tfidf\", TfidfTransformer()),\n",
        "        (\"clf\", SelfTrainingClassifier(SGDClassifier(**sdg_params), verbose=True)),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "3gNSgU9S0tN1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a function for a classification report**"
      ],
      "metadata": {
        "id": "aXhq1Peu0S00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):\n",
        "    print(\"Number of training samples:\", len(X_train))\n",
        "    print(\"Unlabeled samples in training set:\", sum(1 for x in y_train if x == -1)) #if x == 'NaN'\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    #print(\"y Train\", y_train)\n",
        "    print(\"y Predict\",y_pred)\n",
        "    print(\"y Test\",y_test)\n",
        "\n",
        "    print(\n",
        "        \"Micro-averaged F1 score on test set: %0.3f\"\n",
        "        % f1_score(y_test, y_pred, average=\"micro\")\n",
        "    )\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test,y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred,zero_division=1))\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "id": "vEtYi3z20S7l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data**"
      ],
      "metadata": {
        "id": "-EFccLfJ0Jpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, stratify=y_labeled, random_state=42)"
      ],
      "metadata": {
        "id": "Xe0jIcaq0Jw7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supervised SGDClassifier on the labeled data**"
      ],
      "metadata": {
        "id": "0xoWkJmgyqnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Supervised SGDClassifier on the labeled data:\")\n",
        "eval_and_print_metrics(pipeline, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-49aaJ-lyquw",
        "outputId": "3f2a7412-d941-4dcf-ef90-02f98848dc23",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supervised SGDClassifier on the labeled data:\n",
            "Number of training samples: 501\n",
            "Unlabeled samples in training set: 0\n",
            "y Predict ['surprise' 'joy' 'surprise' 'surprise' 'neutral' 'joy' 'joy' 'fear'\n",
            " 'disgust' 'surprise' 'anger' 'surprise' 'joy' 'joy' 'joy' 'disgust'\n",
            " 'anger' 'sadness' 'neutral' 'sadness' 'sadness' 'surprise' 'joy'\n",
            " 'neutral' 'fear' 'disgust' 'fear' 'disgust' 'surprise' 'anger' 'disgust'\n",
            " 'neutral' 'surprise' 'neutral' 'sadness' 'sadness' 'disgust' 'surprise'\n",
            " 'disgust' 'surprise' 'sadness' 'sadness' 'neutral' 'fear' 'sadness'\n",
            " 'surprise' 'disgust' 'neutral' 'sadness' 'surprise' 'sadness' 'joy'\n",
            " 'anger' 'sadness' 'fear' 'neutral' 'fear' 'neutral' 'surprise' 'joy'\n",
            " 'fear' 'neutral' 'neutral' 'joy' 'sadness' 'surprise' 'joy' 'neutral'\n",
            " 'disgust' 'joy' 'surprise' 'sadness' 'fear' 'anger' 'neutral' 'fear'\n",
            " 'surprise' 'disgust' 'surprise' 'sadness' 'surprise' 'fear' 'disgust'\n",
            " 'fear' 'neutral' 'neutral' 'joy' 'neutral' 'joy' 'neutral' 'disgust'\n",
            " 'surprise' 'joy' 'sadness' 'joy' 'sadness' 'surprise' 'sadness' 'joy'\n",
            " 'fear' 'sadness' 'neutral' 'sadness' 'joy' 'neutral' 'disgust' 'disgust'\n",
            " 'sadness' 'fear' 'fear' 'neutral' 'fear' 'surprise' 'anger' 'fear'\n",
            " 'sadness' 'surprise' 'surprise' 'neutral' 'joy' 'surprise' 'surprise'\n",
            " 'neutral' 'joy' 'neutral' 'disgust']\n",
            "y Test 304     surprise\n",
            "57           joy\n",
            "912     surprise\n",
            "3367    surprise\n",
            "2820     neutral\n",
            "          ...   \n",
            "703        anger\n",
            "2687     neutral\n",
            "3339    surprise\n",
            "1674     sadness\n",
            "4890    surprise\n",
            "Name: emotions_, Length: 126, dtype: object\n",
            "Micro-averaged F1 score on test set: 0.587\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 4  1  0  1  2  1  2]\n",
            " [ 1  8  2  1  1  2  1]\n",
            " [ 0  1 10  1  0  3  1]\n",
            " [ 0  0  2 14  0  2  2]\n",
            " [ 0  1  1  0 14  1  3]\n",
            " [ 1  1  0  1  5 10  2]\n",
            " [ 0  3  1  2  1  2 14]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.67      0.36      0.47        11\n",
            "     disgust       0.53      0.50      0.52        16\n",
            "        fear       0.62      0.62      0.62        16\n",
            "         joy       0.70      0.70      0.70        20\n",
            "     neutral       0.61      0.70      0.65        20\n",
            "     sadness       0.48      0.50      0.49        20\n",
            "    surprise       0.56      0.61      0.58        23\n",
            "\n",
            "    accuracy                           0.59       126\n",
            "   macro avg       0.60      0.57      0.58       126\n",
            "weighted avg       0.59      0.59      0.58       126\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (126) does not match length of index (5722)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2fce15f25edb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Supervised SGDClassifier on the labeled data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meval_and_print_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-c0f2452451c6>\u001b[0m in \u001b[0;36meval_and_print_metrics\u001b[0;34m(clf, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Add the predicted labels to the final DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3948\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3950\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3952\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4141\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4142\u001b[0m         \"\"\"\n\u001b[0;32m-> 4143\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4870\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4871\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (126) does not match length of index (5722)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self Training Classifier on the labeled data**"
      ],
      "metadata": {
        "id": "ZOhbZGWzz6wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Self Training Classifier on the labeled data:\")\n",
        "eval_and_print_metrics(st_pipeline, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KlRuPUTz62U",
        "outputId": "95b089a4-6a7a-458a-f456-46fb13aac035"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self Training Classifier on the labeled data:\n",
            "Number of training samples: 501\n",
            "Unlabeled samples in training set: 0\n",
            "Micro-averaged F1 score on test set: 0.563\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 3  3  0  1  2  0  2]\n",
            " [ 1  7  1  1  1  3  2]\n",
            " [ 0  3  9  0  0  2  2]\n",
            " [ 1  0  1 14  0  2  2]\n",
            " [ 1  1  1  0 13  1  3]\n",
            " [ 0  1  1  2  5  9  2]\n",
            " [ 0  3  1  1  1  1 16]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.50      0.27      0.35        11\n",
            "     disgust       0.39      0.44      0.41        16\n",
            "        fear       0.64      0.56      0.60        16\n",
            "         joy       0.74      0.70      0.72        20\n",
            "     neutral       0.59      0.65      0.62        20\n",
            "     sadness       0.50      0.45      0.47        20\n",
            "    surprise       0.55      0.70      0.62        23\n",
            "\n",
            "    accuracy                           0.56       126\n",
            "   macro avg       0.56      0.54      0.54       126\n",
            "weighted avg       0.57      0.56      0.56       126\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/semi_supervised/_self_training.py:212: UserWarning: y contains no unlabeled samples\n",
            "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self Training Classifier on the labeled and unlabeled data**"
      ],
      "metadata": {
        "id": "bAacD-vPyq8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manage Labeled and Unlabeled Data**"
      ],
      "metadata": {
        "id": "-k79s34Oy8Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_indices = X_test.index\n",
        "#print(\"TEST INDICES\",test_indices)\n",
        "\n",
        "# Exclude test data from X_labeled and y_labeled based on the identified indices\n",
        "X_labeled_filtered = X_labeled.drop(index=test_indices, errors='ignore')\n",
        "y_labeled_filtered = y_labeled.drop(index=test_indices, errors='ignore')\n",
        "\n",
        "# Concatenate the filtered labeled data with the unlabeled data\n",
        "X=X_combined = pd.concat([X_labeled_filtered, X_unlabeled])\n",
        "y=y_combined = pd.concat([y_labeled_filtered, y_unlabeled])"
      ],
      "metadata": {
        "id": "s8Mo7t2vy8O3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mapping Labels**"
      ],
      "metadata": {
        "id": "FNiE_v17y8X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping for labels\n",
        "# label_mapping = {'Positive': 1, 'Negative': 0, -1:-1 }\n",
        "label_mapping = {\n",
        "    'anger': 1,\n",
        "    'joy': 2,\n",
        "    'sadness': 3,\n",
        "    'fear': 4,\n",
        "    'disgust': 5,\n",
        "    'surprise': 6,\n",
        "    'neutral': 7,\n",
        "    -1:-1\n",
        "}\n",
        "# Apply the mapping to labels\n",
        "y  = [label_mapping[label] for label in y]\n",
        "#print(y)\n",
        "y_test  = [label_mapping[label] for label in y_test]\n",
        "#print(y_test)"
      ],
      "metadata": {
        "id": "37vfBIrVy8gD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Self Training Classifier on the labeled and unlabeled data:\")\n",
        "eval_and_print_metrics(st_pipeline, X, y, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yJaJenyyyrEF",
        "outputId": "b8dfc5c7-8d29-49d4-d91e-8767a052ee1f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self Training Classifier on the labeled and unlabeled data:\n",
            "Number of training samples: 501\n",
            "Unlabeled samples in training set: 0\n",
            "y Predict [6 2 6 6 7 2 2 4 5 6 1 6 2 2 2 5 1 3 7 3 3 6 2 7 4 5 4 5 6 5 5 7 6 7 3 3 3\n",
            " 6 5 6 3 7 1 4 3 6 5 7 3 6 3 2 4 3 4 2 4 7 7 2 4 7 7 2 3 6 2 5 5 2 4 6 6 1\n",
            " 7 4 6 5 6 3 6 4 5 4 7 7 2 7 2 2 3 6 2 3 2 6 2 3 2 4 3 7 3 2 7 5 5 3 4 6 7\n",
            " 4 6 5 4 3 6 6 7 2 6 6 7 2 7 5]\n",
            "y Test [6, 2, 6, 6, 7, 3, 6, 7, 5, 6, 1, 1, 2, 2, 2, 6, 5, 1, 7, 7, 6, 7, 2, 3, 2, 5, 4, 5, 6, 1, 5, 7, 3, 7, 4, 2, 5, 6, 4, 5, 4, 3, 7, 6, 3, 7, 7, 7, 5, 6, 3, 2, 3, 2, 4, 7, 5, 7, 6, 2, 4, 7, 3, 1, 3, 6, 5, 3, 6, 2, 4, 5, 4, 1, 1, 4, 7, 5, 3, 4, 6, 5, 3, 2, 7, 6, 2, 7, 2, 3, 5, 6, 2, 3, 2, 6, 2, 3, 2, 4, 3, 5, 3, 2, 1, 5, 1, 3, 4, 4, 7, 4, 2, 1, 4, 3, 6, 6, 7, 4, 6, 1, 7, 6, 3, 6]\n",
            "Micro-averaged F1 score on test set: 0.532\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 2  1  1  0  3  2  2]\n",
            " [ 0 15  2  2  0  1  0]\n",
            " [ 0  2  9  1  2  2  4]\n",
            " [ 0  1  3  9  1  2  0]\n",
            " [ 1  1  3  2  6  2  1]\n",
            " [ 0  2  1  1  3 14  2]\n",
            " [ 1  1  1  1  1  3 12]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.18      0.27        11\n",
            "           2       0.65      0.75      0.70        20\n",
            "           3       0.45      0.45      0.45        20\n",
            "           4       0.56      0.56      0.56        16\n",
            "           5       0.38      0.38      0.38        16\n",
            "           6       0.54      0.61      0.57        23\n",
            "           7       0.57      0.60      0.59        20\n",
            "\n",
            "    accuracy                           0.53       126\n",
            "   macro avg       0.52      0.50      0.50       126\n",
            "weighted avg       0.53      0.53      0.52       126\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/semi_supervised/_self_training.py:212: UserWarning: y contains no unlabeled samples\n",
            "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (126) does not match length of index (5722)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-0d5155e9edab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Self Training Classifier on the labeled and unlabeled data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meval_and_print_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-c0f2452451c6>\u001b[0m in \u001b[0;36meval_and_print_metrics\u001b[0;34m(clf, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Add the predicted labels to the final DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3948\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3950\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3952\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4141\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4142\u001b[0m         \"\"\"\n\u001b[0;32m-> 4143\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4870\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4871\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (126) does not match length of index (5722)"
          ]
        }
      ]
    }
  ]
}